<!DOCTYPE html>
<html class="no-js">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Hanscau's Projects and Blogs</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" href="../css/common.inverted.min.css">
    <link rel="stylesheet" href="../css/common.tablet.min.css">
    <link rel="stylesheet" href="../css/common.mobile.min.css">
    <link href="https://fonts.googleapis.com/css?family=Noto+Sans+JP&display=swap" rel="stylesheet">

</head>

<body>
    <div class="navbar">
        <a class="navbar__title" href="../index.html">Hanscau's</a>
        <div class="spacer"></div>
        <a href="../index.html" class="navbar__links">Projects and Blogs</a>
        <a href="../art.html" class="navbar__links">Art</a>
        <a href="../about.html" class="navbar__links">About</a>
        <nav class="navbar__container">
            <input type="checkbox" id="trigger" class="navbar__input" />
            <label class="navbar__label" aria-label="open main navigation" for="trigger"><span
                    class="navbar__label__span"></span></label>
            <div class="navbar__menu">
                <div class="navbar__spacer"></div>
                <a href="../index.html" class="navbar__menu__links">Projects and Blogs</a>
                <a href="../art.html" class="navbar__menu__links">Art</a>
                <a href="../about.html" class="navbar__menu__links">About</a>
            </div>
        </nav>
    </div>
    <div class="header">
        <p class="header__title--small">Object Detection</p>
        <p class="header__desc">物体検出</p>
    </div>

    <div class="content">

        <p>One of my project require me to use Object Detection to detect ping pong ball
            so that it can navigate to it. Thus, I need a real-time object detection software
            to do this. Something that is fast enough to detect the object in realtime and
            without using so much computing power (Since I need it to run in a Raspberry Pi).</p>
        <p>So here I am trying to use...</p>
        <h3>YOLO:Real-Time Object Detection</h3>
        <div class="hr"></div>
        <h3>Resources</h3>
        <p>Linux Ubuntu 16.04</p>
        <p>CUDA Toolkit 9.0</p>
        <p>OpenCV 3.4.0</p>
        <p>Darknet - YOLO</p>
        <p>Object to detect</p>
        <p>Webcam</p>
        <div class="note">NOTE: Only use the version denotated above. Other version might not be compatible
            with each other</div>
        <p>Assuming you have done everything above and there was no problem with it, we can start
            doing the Object Detection stuff</p>
        <p>Start by setting up YOLO</p>
        <p>Open Terminal and start installation</p>
        <div class="note">NOTE: "Ctrl + Alt + T" will open up Terminal</div>
        <p>If git is not installed, run the following</p>
        <div class="code">
            sudo apt-get install git
        </div>
        <p>If or after git is installed, run the folloing</p>
        <div class="code">
            cd ~<br>
            git clone https://github.com/pjreddie/darknet<br>
        </div>
        <p>Then go to the darknet folder that you have clone and open up "makefile"</p>
        <p>In the file, set OpenCv=1 and CUDA=1. Then from the folder, open terminal and run the following</p>
        <div class="code">
            make
        </div>
        <h3>Testing YOLO</h3>
        <p>While still in the darknet directory, run this to get the sample weight(model) for testing</p>
        <div class="code">
            wget https://pjreddie.com/media/files/yolov3.weights
        </div>
        <p>Then, still in the same directory, run the detector for testing</p>
        <div class="code">
            ./darknet detect cfg/yolov3.cfg yolov3.weights data/dog.jpg
        </div>
        <p>After some text flash by, an image will be produced in the same directory</p>
        <p>If you navigate to the folder /home/(user_name)/darknet, there will be a prediction.jpg</p>
        <img src="img/prediction.png" alt="Prediction image" id="blogImg">
        <p>If you see the image above, it means that YOLO is correctly installed!</p>
        <p>Now with YOLO installed properly(FOR NOW), we can begin preparing for training</p>
        <p>Download the following files: <a href="resources/dataset_preparing.rar">Preparing Dataset</a></p>
        <p>Download and extract the file to Desktop</p>
        <p>Now, get the item that you want to detect and shoot a 2 minute video of it</p>
        <!-- INSERT A GIF OF THE PING PONG VIDEO-->
        <p>After taking a video of it, put the video file inside dataset_preparing/recordVideo</p>
        <p>Using a text editor, open up separate.py and change the following. In line 2</p>
        <div class="code">
            #change "WIN_20180903_14_23_55_Pro.mp4" to your own video file name<br>
            #Don't forget your video extension<br>
            2. vidcap = cv2.VideoCapture('WIN_20180903_14_23_55_Pro.mp4')
        </div>
        <p>After changing it to your own video, run the python script</p>
        <p>Right click the blank space in the folder and Open in Terminal. This will open up
            terminal and set the directory to the folder where the terminal is envoked</p>
        <img src='img/show_terminal.jpg' alt="show terminal" id="blogImg">
        <p>And run the following code</p>
        <div class="code">
            python separate.py
        </div>
        <p>When the code finish running, go to dataset_preparing/recordVideo/Images. There you should be
            video sliced into many image files. Scroll to the bottom and keep note of the amount of image
            your video have been sliced into</p>
        <p>Next in the folder recordVideo, use a text editor to open up generate_test_data.py and under line
            15. Change the value that is there previously (117 in this case) and change it to the amount of image that
            have
            been sliced</p>
        <div class="code">
            15. for f in range(1, 117):<br>
            #change 117 into the amount of image that you have<br>
            15. for f in range(1,x);<br>
            #x = amount of image that you have<br>
        </div>
        <p>Here is an example: </p>
        <img src="img/total_img.jpg" alt="My img total" id="blogImg">
        <p>For my case, I had 135 images. Here is how my generate_test_data.py looked</p>
        <img src="img/separatepy.jpg" alt="Generate test data" id="blogImg">
        <p>Save and close the file and again opening up Terminal in that directory, run the python script</p>
        <div class="code">
            python generate_test_data
        </div>
        <p>This script will automatically divide your test images into two different folder, one for training and the
            other for testing</p>
        <p>Now to label the images</p>
        <h3>Labeling</h3>
        <p>For labeling I will be using a image labeling app that someone has made<p>
                <p>Download the file here: <a href="https://github.com/tzutalin/labelImg">labelImg</a></p>
                <p>On the github website itself, there are instructions of the prerequesite needed for the application
                    to work.
                    Open a terminal and input the following, entering 'Y' if prompted</p>
                <div class="code">
                    sudo apt-get install pyqt4-dev-tools<br>
                    sudo pip install lxml<br>
                    sudo pip install python-resources
                </div>
                <p>After all the repositories are installed, go to the directory that you downloaded it to
                    and run the python code</p>
                <p>We will start by labeling the images for training</p>

                <p>In the image labelling application, change the open directory to the dataset_preparing folder you
                    downloaded earlier,
                    in dataset_preparing/recordVideo/VOCdevkit/VOC2012/JPEGImages</p>
                <p>Then change the save directory to dataset_preparing/recordVideo/VOCdevkit/VOC2012/Annotations</p>
                <p>Your image should appear in the application and you are free to label!</p>
                <p>Basically there are 3 steps that you have to do for labeling</p>
                <p>1. Draw a rectangle over your object<br>2. Save the labeling<br>3. Next image</p>
                <div class="note">SHORTCUT LEGEND:<br>
                    [w] - rectangular label tool<br>
                    [d] - next image<br>
                    [a] - previous image<br>
                    [ctrl + s] - save (much surprise)</div>
                <p>Rinse and repeat for all your images until you are done.</p>
                <p>After you are finished, feel free to look through all your labeled images and
                    bask in the glory of your hard work!!! Then, after taking a huge sigh, change the open
                    diretory to dataset_preparing/recordVideo/VOCdevkit/VOC2007/JPEGImages and save directory
                    to dataset_preparing/recordVideo/VOCdevkit/VOC2007/Annotations and GET TO LABELING AGAIN!!</p>
                <div class="note">Don't forget to save!</div>
                <p>If you dont understand the directory that you have to get the image from and where
                    to save the labels to, here is a tree diagram for the downloaded folder which you can use to just
                    navigate to where you should do your stuff.</p>
                <!-- ADD PICTURE OF DIRECTORY MAP -->
                <p>Now go to the folder both in VOC2007 and VOC2012 \ImageSets\Main, there is a python script
                    called list_all_image_name.py, run it</p>
                <p>Still good? if the answer is yes lets move on, download the next
                    folder here:
                    <a href="resources/training.rar">Training file</a>
                    . If not, go take a walk out, its too nice a day to waste it staring at a computer
                    screen :D</p>
                <!--ADD TRAINING RAR FILE-->
                <p>Unzip the file and it is recomended that it is put on the desktop</p>
                <p>Now, from the dataset_preparing folder, copy the entire folder VOCdevkit into the
                    downloaded folder("training" folder)</p>
                <p>Then do the following</p>
                <p>1. in allclass.names, add the name of the labeled image</p>
                <p>2. in voc_label.py, under classes. Add all your class in a list fashion.</p>
                <div class="code">
                    #Example<br>
                    classes = ["itemOne","itemTwo","itemThree"]
                </div>
                <p>3. run the python script voc_label.py. This should create 2 text file called "2007_test.txt" and
                    "2012_trainval.txt"</p>
                <p>4. in yolov2.data, change the data accordingly.</p>
                <p>classes - number of different label that you have <br>(1 for me since I only have
                    "ping_pong_ball")<br>
                    train - path of the trainval.txt (should be in the "training" folder)<br>
                    valid - path of the test.txt (should also be in the "training" folder)<br>
                    names - path to allclass.names (in the "training" folder)<br>
                    backup - path to the folder yolov2 (in "training" folder)<br></p>
                <p>You need to change this as different computer have different username and thus different path</p>
                <p>5. from your darnet installation folder (should be in root) go into config and copy any cfg file you
                    want(I will be using yolov2.cfg). Paste them into the "training" folder</p>
                <p>6. Again from darnet folder, copy the entire "data" folder into your "training" folder</p>
                <p>7. In the .cfg file that you want to use</p>
                <p>Under [net] set batch to 16 and subdivisions to 4 (should be in line 6 and 7 respectively if you are
                    using yolov2.cfg)</p>
                <p>Scroll all the way down, and under [region] set classes to the number of class you have (line 244 in
                    yolov2.cfg)</p>
                <p>A little above it, under [convolutional] with activation = linear, set <br>filters to (classes + 5)*5
                    (line 237 in yolov2.cfg)</p>
                <p>Save the .cfg file</p>
                <p>Now you are ready to start training</p>
                <p>Open a terminal in the "training" folder directory and run the following</p>
                <div class="code">
                    [path to darknet] detector train [path to .data] [path to .cfg] darknet19_448.conv.23<br>
                    #Example: /home/hanscau/darknet/darknet detector train yolov2.data yolov2.cfg darknet19_448.conv.23
                </div>
                <p>if you have been putting the folder in the prefered pathing, you just have to change "hanscau" with
                    your own user name and run the command. If not, then change the "/home/hanscau/darknet/darknet" to
                    where you installed darknet</p>
                <p>This should run some code and start training your model</p>
                <p>Look out for the ave IOU, the higher it goes, the more accurate the training</p>
                <!-- TODO: FIND OUT WHAT SOMETHING IS -->
                <p>The training will automatically create a model after every 100 images interval, then after 900 images
                    it will create a model at a 10000 image interval</p>
                <p> the model will be saved in the "yolov2" folder in the "training" folder</p>
                <div class="note">NOTE: The images that they use to train does not have to correspond to the number of
                    images that you supplied. Meaning
                    it can train until 10 000 iteration even though you only supplied 100++</div>
                <p>After the desired model is done, you can cancel the training. Press Ctrl + C to cancel it</p>
                <div class="note">NOTE: You can use [Ctrl + C] to cancel most scripts or application</div>
                <p>Now for the part where all of us are waiting for</p>
                <h3>DEMO</h3>
                <p>Open a terminal in the "training" folder and run the following</p>
                <div class="code">
                    [path to darknet] demo detector [path to .data file] [path to .cfg file] [path to
                    .weights(model)]<br>
                    #Example: /home/hanscau/darknet/darknet detector demo yolov2.data yolov2.cfg
                    yolov2/yolov2_900.weights
                </div>
                <p>Similarly, if you have been following, you just have to change the path to darknet and it should work
                </p>
                <p>Your webcam will be initialised and if you were to put your item infront of you webcam the program
                    should draw
                    a bounding box around it with your label on it</p>
                <!-- TODO: ADD PICS -->
                <p>And you are done</p>
                <p>After training, the file you need will just be the .cfg file and .weight file</p>
    </div>

    <div class="footer">&copy;Hanscau 2020</div>
</body>

</html>